#!/bin/bash

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘        ğŸ¤– Instalador de Modelos Ollama                      â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Escolha qual modelo deseja instalar:"
echo ""
echo "1) TinyLlama 1.1B    (637 MB)  - Mais leve, respostas rÃ¡pidas"
echo "2) Phi 2.7B          (1.6 GB)  - Equilibrado, boa qualidade"
echo "3) Gemma2 2B         (1.6 GB)  - Google, boa qualidade"
echo "4) Llama 3.2 3B      (2.0 GB)  - Meta, muito bom"
echo "5) Todos os leves    (1-3)     - Instala TinyLlama, Phi e Gemma2"
echo "6) Cancelar"
echo ""
read -p "Digite sua escolha (1-6): " choice

case $choice in
    1)
        echo ""
        echo "ğŸ“¦ Baixando TinyLlama 1.1B (637 MB)..."
        docker exec observatorio_ollama ollama pull tinyllama:1.1b
        echo "âœ… TinyLlama instalado!"
        ;;
    2)
        echo ""
        echo "ğŸ“¦ Baixando Phi 2.7B (1.6 GB)..."
        docker exec observatorio_ollama ollama pull phi:2.7b
        echo "âœ… Phi instalado!"
        ;;
    3)
        echo ""
        echo "ğŸ“¦ Baixando Gemma2 2B (1.6 GB)..."
        docker exec observatorio_ollama ollama pull gemma2:2b
        echo "âœ… Gemma2 instalado!"
        ;;
    4)
        echo ""
        echo "ğŸ“¦ Baixando Llama 3.2 3B (2.0 GB)..."
        docker exec observatorio_ollama ollama pull llama3.2:3b
        echo "âœ… Llama 3.2 instalado!"
        ;;
    5)
        echo ""
        echo "ğŸ“¦ Baixando TinyLlama 1.1B (637 MB)..."
        docker exec observatorio_ollama ollama pull tinyllama:1.1b
        echo ""
        echo "ğŸ“¦ Baixando Phi 2.7B (1.6 GB)..."
        docker exec observatorio_ollama ollama pull phi:2.7b
        echo ""
        echo "ğŸ“¦ Baixando Gemma2 2B (1.6 GB)..."
        docker exec observatorio_ollama ollama pull gemma2:2b
        echo "âœ… Todos os modelos leves instalados!"
        ;;
    6)
        echo "âŒ Cancelado."
        exit 0
        ;;
    *)
        echo "âŒ OpÃ§Ã£o invÃ¡lida."
        exit 1
        ;;
esac

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘        âœ… InstalaÃ§Ã£o ConcluÃ­da!                             â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“‹ Modelos instalados:"
docker exec observatorio_ollama ollama list
echo ""
echo "ğŸ” Para testar um modelo:"
echo "   docker exec -it observatorio_ollama ollama run tinyllama:1.1b"
echo ""
echo "ğŸ“š DocumentaÃ§Ã£o completa: OLLAMA_GUIDE.md"
